<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Papers on AI Digest</title>
    <link>/paper/</link>
    <description>Recent content in Papers on AI Digest</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Apr 2025 10:49:33 +0000</lastBuildDate>
    <atom:link href="/paper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>$	exttt{Complex-Edit}$: CoT-Like Instruction Generation for Complexity-Controllable Image Editing Benchmark</title>
      <link>/paper/texttt-complex-edit-cot-like-instruction-generation-for-complexity-controllable-image-editing-benchmark-1744973373106-909992/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/texttt-complex-edit-cot-like-instruction-generation-for-complexity-controllable-image-editing-benchmark-1744973373106-909992/</guid>
      <description>&lt;p&gt;We introduce $\texttt{Complex-Edit}$, a comprehensive benchmark designed to systematically evaluate instruction-based image editing models across instructions of varying complexity. To develop this benchmark, we harness GPT-4o to automatically collect a diverse set of editing instructions at scale. Our approach follows a well-structured &lt;code&gt;Chain-of-Edit&#39;&#39; pipeline: we first generate individual atomic editing tasks independently and then integrate them to form cohesive, complex instructions. Additionally, we introduce a suite of metrics to assess various aspects of editing performance, along with a VLM-based auto-evaluation pipeline that supports large-scale assessments. Our benchmark yields several notable insights: 1) Open-source models significantly underperform relative to proprietary, closed-source models, with the performance gap widening as instruction complexity increases; 2) Increased instructional complexity primarily impairs the models&#39; ability to retain key elements from the input images and to preserve the overall aesthetic quality; 3) Decomposing a complex instruction into a sequence of atomic steps, executed in a step-by-step manner, substantially degrades performance across multiple metrics; 4) A straightforward Best-of-N selection strategy improves results for both direct editing and the step-by-step sequential approach; and 5) We observe a &lt;/code&gt;curse of synthetic data&amp;rsquo;&amp;rsquo;: when synthetic data is involved in model training, the edited images from such models tend to appear increasingly synthetic as the complexity of the editing instructions rises &amp;ndash; a phenomenon that intriguingly also manifests in the latest GPT-4o outputs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A general language model for peptide identification</title>
      <link>/paper/a-general-language-model-for-peptide-identification-1744973373106-916611/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/a-general-language-model-for-peptide-identification-1744973373106-916611/</guid>
      <description>&lt;p&gt;Advances in peptide identification are revolutionizing our ability to decipher protein functions and accelerate therapeutic discovery. We present PDeepPP, a deep learning framework that integrates pretrained protein language models with parallel transformer-CNN architectures, achieving state-of-the-art performance in peptide characterization tasks. The model&amp;rsquo;s hybrid architecture demonstrates unique capabilities in capturing both local sequence motifs and global structural features, as evidenced by 29% improved cluster separation in UMAP visualizations compared to conventional approaches. Evaluated across 33 biological recognition tasks - including post-translational modification site prediction and bioactive peptide identification - PDeepPP outperformed existing methods in 25 tasks with average AUC improvements of 4.2%. Notably, it achieved 0.9726 accuracy with PR AUC 0.9977 in antimicrobial peptide detection while reducing false negatives by 37.5% in antimalarial recognition scenarios. This framework enables accurate large-scale peptide analysis, achieving 218* acceleration over sequence-alignment-based methods while maintaining 99.5% specificity in critical glycosylation site detection.PDeepPP establishes a new paradigm for computational peptide analysis through its synergistic architecture design, enabling rapid yet precise functional annotation that bridges molecular pattern recognition with translational biomedical applications.We have made our implementation, including code, data, and pretrained models, publicly available via GitHub (&lt;a href=&#34;https://github.com/fondress/PDeepPP&#34;&gt;https://github.com/fondress/PDeepPP&lt;/a&gt;) and Hugging Face (&lt;a href=&#34;https://huggingface.co/fondress/PDeppPP)&#34;&gt;https://huggingface.co/fondress/PDeppPP)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal Control with Time Scaling</title>
      <link>/paper/a-new-semidefinite-relaxation-for-linear-and-piecewise-affine-optimal-control-with-time-scaling-1744973373105-262746/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/a-new-semidefinite-relaxation-for-linear-and-piecewise-affine-optimal-control-with-time-scaling-1744973373105-262746/</guid>
      <description>&lt;p&gt;We introduce a semidefinite relaxation for optimal control of linear systems with time scaling. These problems are inherently nonconvex, since the system dynamics involves bilinear products between the discretization time step and the system state and controls. The proposed relaxation is closely related to the standard second-order semidefinite relaxation for quadratic constraints, but we carefully select a subset of the possible bilinear terms and apply a change of variables to achieve empirically tight relaxations while keeping the computational load light. We further extend our method to handle piecewise-affine (PWA) systems by formulating the PWA optimal-control problem as a shortest-path problem in a graph of convex sets (GCS). In this GCS, different paths represent different mode sequences for the PWA system, and the convex sets model the relaxed dynamics within each mode. By combining a tight convex relaxation of the GCS problem with our semidefinite relaxation with time scaling, we can solve PWA optimal-control problems through a single semidefinite program.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis</title>
      <link>/paper/aerialmegadepth-learning-aerial-ground-reconstruction-and-view-synthesis-1744973373105-832844/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/aerialmegadepth-learning-aerial-ground-reconstruction-and-view-synthesis-1744973373105-832844/</guid>
      <description>&lt;p&gt;We explore the task of geometric reconstruction of images captured from a mixture of ground and aerial views. Current state-of-the-art learning-based approaches fail to handle the extreme viewpoint variation between aerial-ground image pairs. Our hypothesis is that the lack of high-quality, co-registered aerial-ground datasets for training is a key reason for this failure. Such data is difficult to assemble precisely because it is difficult to reconstruct in a scalable way. To overcome this challenge, we propose a scalable framework combining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google Earth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The pseudo-synthetic data simulates a wide range of aerial viewpoints, while the real, crowd-sourced images help improve visual fidelity for ground-level images where mesh-based renderings lack sufficient detail, effectively bridging the domain gap between real images and pseudo-synthetic renderings. Using this hybrid dataset, we fine-tune several state-of-the-art algorithms and achieve significant improvements on real-world, zero-shot aerial-ground tasks. For example, we observe that baseline DUSt3R localizes fewer than 5% of aerial-ground pairs within 5 degrees of camera rotation error, while fine-tuning with our data raises accuracy to nearly 56%, addressing a major failure point in handling large viewpoint changes. Beyond camera estimation and scene reconstruction, our dataset also improves performance on downstream tasks like novel-view synthesis in challenging aerial-ground scenarios, demonstrating the practical value of our approach in real-world applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Aligning Constraint Generation with Design Intent in Parametric CAD</title>
      <link>/paper/aligning-constraint-generation-with-design-intent-in-parametric-cad-1744973373104-841307/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/aligning-constraint-generation-with-design-intent-in-parametric-cad-1744973373104-841307/</guid>
      <description>&lt;p&gt;We adapt alignment techniques from reasoning LLMs to the task of generating engineering sketch constraints found in computer-aided design (CAD) models. Engineering sketches consist of geometric primitives (e.g. points, lines) connected by constraints (e.g. perpendicular, tangent) that define the relationships between them. For a design to be easily editable, the constraints must effectively capture design intent, ensuring the geometry updates predictably when parameters change. Although current approaches can generate CAD designs, an open challenge remains to align model outputs with design intent, we label this problem `design alignment&amp;rsquo;. A critical first step towards aligning generative CAD models is to generate constraints which fully-constrain all geometric primitives, without over-constraining or distorting sketch geometry. Using alignment techniques to train an existing constraint generation model with feedback from a constraint solver, we are able to fully-constrain 93% of sketches compared to 34% when using a na\&amp;ldquo;ive supervised fine-tuning (SFT) baseline and only 8.9% without alignment. Our approach can be applied to any existing constraint generation model and sets the stage for further research bridging alignment strategies between the language and design domains.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Antidistillation Sampling</title>
      <link>/paper/antidistillation-sampling-1744973373106-823669/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/antidistillation-sampling-1744973373106-823669/</guid>
      <description>&lt;p&gt;Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. \emph{Antidistillation sampling} provides exactly this capability. By strategically modifying a model&amp;rsquo;s next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model&amp;rsquo;s practical utility. For further details, see &lt;a href=&#34;https://antidistillation.com&#34;&gt;https://antidistillation.com&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Differentially Private Sequential Learning</title>
      <link>/paper/differentially-private-sequential-learning-1744973373106-176790/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/differentially-private-sequential-learning-1744973373106-176790/</guid>
      <description>&lt;p&gt;In a differentially private sequential learning setting, agents introduce endogenous noise into their actions to maintain privacy. Applying this to a standard sequential learning model leads to different outcomes for continuous vs. binary signals. For continuous signals with a nonzero privacy budget, we introduce a novel smoothed randomized response mechanism that adapts noise based on distance to a threshold, unlike traditional randomized response, which applies uniform noise. This enables agents&amp;rsquo; actions to better reflect both private signals and observed history, accelerating asymptotic learning speed to $\Theta_{\epsilon}(\log(n))$, compared to $\Theta(\sqrt{\log(n)})$ in the non-private regime where privacy budget is infinite. Moreover, in the non-private setting, the expected stopping time for the first correct decision and the number of incorrect actions diverge, meaning early agents may make mistakes for an unreasonably long period. In contrast, under a finite privacy budget $\epsilon \in (0,1)$, both remain finite, highlighting a stark contrast between private and non-private learning. Learning with continuous signals in the private regime is more efficient, as smooth randomized response enhances the log-likelihood ratio over time, improving information aggregation. Conversely, for binary signals, differential privacy noise hinders learning, as agents tend to use a constant randomized response strategy before an information cascade forms, reducing action informativeness and hampering the overall process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Digital Twin Generation from Visual Data: A Survey</title>
      <link>/paper/digital-twin-generation-from-visual-data-a-survey-1744973373105-296715/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/digital-twin-generation-from-visual-data-a-survey-1744973373105-296715/</guid>
      <description>&lt;p&gt;This survey explores recent developments in generating digital twins from videos. Such digital twins can be used for robotics application, media content creation, or design and construction works. We analyze various approaches, including 3D Gaussian Splatting, generative in-painting, semantic segmentation, and foundation models highlighting their advantages and limitations. Additionally, we discuss challenges such as occlusions, lighting variations, and scalability, as well as potential future research directions. This survey aims to provide a comprehensive overview of state-of-the-art methodologies and their implications for real-world applications. Awesome list: &lt;a href=&#34;https://github.com/ndrwmlnk/awesome-digital-twins&#34;&gt;https://github.com/ndrwmlnk/awesome-digital-twins&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Expert Failures Improves LLM Agent Tuning</title>
      <link>/paper/exploring-expert-failures-improves-llm-agent-tuning-1744973373106-515006/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/exploring-expert-failures-improves-llm-agent-tuning-1744973373106-515006/</guid>
      <description>&lt;p&gt;Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62% win rate in WebShop, outperforming RFT (53. 6%) and GPT-4 (35. 6%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.&lt;/p&gt;</description>
    </item>
    <item>
      <title>It&#39;s All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization</title>
      <link>/paper/it-s-all-connected-a-journey-through-test-time-memorization-attentional-bias-retention-and-online-optimization-1744973373105-300147/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/it-s-all-connected-a-journey-through-test-time-memorization-attentional-bias-retention-and-online-optimization-1744973373105-300147/</guid>
      <description>&lt;p&gt;Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural architectures, including Transformers, Titans, and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequence models. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Long Range Navigator (LRN): Extending robot planning horizons beyond metric maps</title>
      <link>/paper/long-range-navigator-lrn-extending-robot-planning-horizons-beyond-metric-maps-1744973373105-990610/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/long-range-navigator-lrn-extending-robot-planning-horizons-beyond-metric-maps-1744973373105-990610/</guid>
      <description>&lt;p&gt;A robot navigating an outdoor environment with no prior knowledge of the space must rely on its local sensing to perceive its surroundings and plan. This can come in the form of a local metric map or local policy with some fixed horizon. Beyond that, there is a fog of unknown space marked with some fixed cost. A limited planning horizon can often result in myopic decisions leading the robot off course or worse, into very difficult terrain. Ideally, we would like the robot to have full knowledge that can be orders of magnitude larger than a local cost map. In practice, this is intractable due to sparse sensing information and often computationally expensive. In this work, we make a key observation that long-range navigation only necessitates identifying good frontier directions for planning instead of full map knowledge. To this end, we propose Long Range Navigator (LRN), that learns an intermediate affordance representation mapping high-dimensional camera images to `affordable&amp;rsquo; frontiers for planning, and then optimizing for maximum alignment with the desired goal. LRN notably is trained entirely on unlabeled ego-centric videos making it easy to scale and adapt to new platforms. Through extensive off-road experiments on Spot and a Big Vehicle, we find that augmenting existing navigation stacks with LRN reduces human interventions at test-time and leads to faster decision making indicating the relevance of LRN. &lt;a href=&#34;https://personalrobotics.github.io/lrn&#34;&gt;https://personalrobotics.github.io/lrn&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MalMixer: Few-Shot Malware Classification with Retrieval-Augmented Semi-Supervised Learning</title>
      <link>/paper/malmixer-few-shot-malware-classification-with-retrieval-augmented-semi-supervised-learning-1744973373106-444305/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/malmixer-few-shot-malware-classification-with-retrieval-augmented-semi-supervised-learning-1744973373106-444305/</guid>
      <description>&lt;p&gt;Recent growth and proliferation of malware have tested practitioners ability to promptly classify new samples according to malware families. In contrast to labor-intensive reverse engineering efforts, machine learning approaches have demonstrated increased speed and accuracy. However, most existing deep-learning malware family classifiers must be calibrated using a large number of samples that are painstakingly manually analyzed before training. Furthermore, as novel malware samples arise that are beyond the scope of the training set, additional reverse engineering effort must be employed to update the training set. The sheer volume of new samples found in the wild creates substantial pressure on practitioners ability to reverse engineer enough malware to adequately train modern classifiers. In this paper, we present MalMixer, a malware family classifier using semi-supervised learning that achieves high accuracy with sparse training data. We present a domain-knowledge-aware data augmentation technique for malware feature representations, enhancing few-shot performance of semi-supervised malware family classification. We show that MalMixer achieves state-of-the-art performance in few-shot malware family classification settings. Our research confirms the feasibility and effectiveness of lightweight, domain-knowledge-aware data augmentation methods for malware features and shows the capabilities of similar semi-supervised classifiers in addressing malware classification issues.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MIB: A Mechanistic Interpretability Benchmark</title>
      <link>/paper/mib-a-mechanistic-interpretability-benchmark-1744973373105-585665/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/mib-a-mechanistic-interpretability-benchmark-1744973373105-585665/</guid>
      <description>&lt;p&gt;How can we know whether new mechanistic interpretability methods achieve real improvements? In pursuit of meaningful and lasting evaluation standards, we propose MIB, a benchmark with two tracks spanning four tasks and five models. MIB favors methods that precisely and concisely recover relevant causal pathways or specific causal variables in neural language models. The circuit localization track compares methods that locate the model components - and connections between them - most important for performing a task (e.g., attribution patching or information flow routes). The causal variable localization track compares methods that featurize a hidden vector, e.g., sparse autoencoders (SAEs) or distributed alignment search (DAS), and locate model features for a causal variable relevant to the task. Using MIB, we find that attribution and mask optimization methods perform best on circuit localization. For causal variable localization, we find that the supervised DAS method performs best, while SAE features are not better than neurons, i.e., standard dimensions of hidden vectors. These findings illustrate that MIB enables meaningful comparisons of methods, and increases our confidence that there has been real progress in the field.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation</title>
      <link>/paper/novel-demonstration-generation-with-gaussian-splatting-enables-robust-one-shot-manipulation-1744973373104-967089/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/novel-demonstration-generation-with-gaussian-splatting-enables-robust-one-shot-manipulation-1744973373104-967089/</guid>
      <description>&lt;p&gt;Visuomotor policies learned from teleoperated demonstrations face challenges such as lengthy data collection, high costs, and limited data diversity. Existing approaches address these issues by augmenting image observations in RGB space or employing Real-to-Sim-to-Real pipelines based on physical simulators. However, the former is constrained to 2D data augmentation, while the latter suffers from imprecise physical simulation caused by inaccurate geometric reconstruction. This paper introduces RoboSplat, a novel method that generates diverse, visually realistic demonstrations by directly manipulating 3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian Splatting (3DGS), directly edit the reconstructed scene, and augment data across six types of generalization with five techniques: 3D Gaussian replacement for varying object types, scene appearance, and robot embodiments; equivariant transformations for different object poses; visual attribute editing for various lighting conditions; novel view synthesis for new camera perspectives; and 3D content generation for diverse object types. Comprehensive real-world experiments demonstrate that RoboSplat significantly enhances the generalization of visuomotor policies under diverse disturbances. Notably, while policies trained on hundreds of real-world demonstrations with additional 2D data augmentation achieve an average success rate of 57.2%, RoboSplat attains 87.8% in one-shot settings across six types of generalization in the real world.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos</title>
      <link>/paper/odhsr-online-dense-3d-reconstruction-of-humans-and-scenes-from-monocular-videos-1744973373105-897309/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/odhsr-online-dense-3d-reconstruction-of-humans-and-scenes-from-monocular-videos-1744973373105-897309/</guid>
      <description>&lt;p&gt;Creating a photorealistic scene and human reconstruction from a single monocular in-the-wild video figures prominently in the perception of a human-centric 3D world. Recent neural rendering advances have enabled holistic human-scene reconstruction but require pre-calibrated camera and human poses, and days of training time. In this work, we introduce a novel unified framework that simultaneously performs camera tracking, human pose estimation and human-scene reconstruction in an online fashion. 3D Gaussian Splatting is utilized to learn Gaussian primitives for humans and scenes efficiently, and reconstruction-based camera tracking and human pose estimation modules are designed to enable holistic understanding and effective disentanglement of pose and appearance. Specifically, we design a human deformation module to reconstruct the details and enhance generalizability to out-of-distribution poses faithfully. Aiming to learn the spatial correlation between human and scene accurately, we introduce occlusion-aware human silhouette rendering and monocular geometric priors, which further improve reconstruction quality. Experiments on the EMDB and NeuMan datasets demonstrate superior or on-par performance with existing methods in camera tracking, human pose estimation, novel view synthesis and runtime. Our project page is at &lt;a href=&#34;https://eth-ait.github.io/ODHSR&#34;&gt;https://eth-ait.github.io/ODHSR&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition</title>
      <link>/paper/pcbear-pose-concept-bottleneck-for-explainable-action-recognition-1744973373106-461681/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/pcbear-pose-concept-bottleneck-for-explainable-action-recognition-1744973373106-461681/</guid>
      <description>&lt;p&gt;Human action recognition (HAR) has achieved impressive results with deep learning models, but their decision-making process remains opaque due to their black-box nature. Ensuring interpretability is crucial, especially for real-world applications requiring transparency and accountability. Existing video XAI methods primarily rely on feature attribution or static textual concepts, both of which struggle to capture motion dynamics and temporal dependencies essential for action understanding. To address these challenges, we propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR), a novel concept bottleneck framework that introduces human pose sequences as motion-aware, structured concepts for video action recognition. Unlike methods based on pixel-level features or static textual descriptions, PCBEAR leverages human skeleton poses, which focus solely on body movements, providing robust and interpretable explanations of motion dynamics. We define two types of pose-based concepts: static pose concepts for spatial configurations at individual frames, and dynamic pose concepts for motion patterns across multiple frames. To construct these concepts, PCBEAR applies clustering to video pose sequences, allowing for automatic discovery of meaningful concepts without manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500, showing that it achieves high classification performance while offering interpretable, motion-driven explanations. Our method provides both strong predictive performance and human-understandable insights into the model&amp;rsquo;s reasoning process, enabling test-time interventions for debugging and improving model behavior.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Perception Encoder: The best visual embeddings are not at the output of the network</title>
      <link>/paper/perception-encoder-the-best-visual-embeddings-are-not-at-the-output-of-the-network-1744973373104-757003/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/perception-encoder-the-best-visual-embeddings-are-not-at-the-output-of-the-network-1744973373104-757003/</guid>
      <description>&lt;p&gt;We introduce Perception Encoder (PE), a state-of-the-art encoder for image and video understanding trained via simple vision-language learning. Traditionally, vision encoders have relied on a variety of pretraining objectives, each tailored to specific downstream tasks such as classification, captioning, or localization. Surprisingly, after scaling our carefully tuned image pretraining recipe and refining with our robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods, language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together with the core contrastive checkpoint, our PE family of models achieves state-of-the-art performance on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&amp;amp;A; and spatial tasks such as detection, depth estimation, and tracking. To foster further research, we are releasing our models, code, and a novel dataset of synthetically and human-annotated videos.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding</title>
      <link>/paper/perceptionlm-open-access-data-and-models-for-detailed-visual-understanding-1744973373104-449434/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/perceptionlm-open-access-data-and-models-for-detailed-visual-understanding-1744973373104-449434/</guid>
      <description>&lt;p&gt;Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about &amp;quot;what&amp;quot;, &amp;quot;where&amp;quot;, &amp;quot;when&amp;quot;, and &amp;quot;how&amp;quot; of a video. We make our work fully reproducible by providing data, training recipes, code &amp;amp; models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quantum algorithm for solving nonlinear differential equations based on physics-informed effective Hamiltonians</title>
      <link>/paper/quantum-algorithm-for-solving-nonlinear-differential-equations-based-on-physics-informed-effective-hamiltonians-1744973373105-412653/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/quantum-algorithm-for-solving-nonlinear-differential-equations-based-on-physics-informed-effective-hamiltonians-1744973373105-412653/</guid>
      <description>&lt;p&gt;We propose a distinct approach to solving linear and nonlinear differential equations (DEs) on quantum computers by encoding the problem into ground states of effective Hamiltonian operators. Our algorithm relies on constructing such operators in the Chebyshev space, where an effective Hamiltonian is a sum of global differential and data constraints. Once the effective Hamiltonian is formed, solutions of differential equations can be obtained using the ground state preparation techniques (e.g. imaginary-time evolution and quantum singular value transformation), bypassing variational search. Unlike approaches based on discrete grids, the algorithm enables evaluation of solutions beyond fixed grid points and implements constraints in the physics-informed way. Our proposal inherits the best traits from quantum machine learning-based DE solving (compact basis representation, automatic differentiation, nonlinearity) and quantum linear algebra-based approaches (fine-grid encoding, provable speed-up for state preparation), offering a robust strategy for quantum scientific computing in the early fault-tolerant era.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Readable Twins of Unreadable Models</title>
      <link>/paper/readable-twins-of-unreadable-models-1744973373105-12004/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/readable-twins-of-unreadable-models-1744973373105-12004/</guid>
      <description>&lt;p&gt;Creating responsible artificial intelligence (AI) systems is an important issue in contemporary research and development of works on AI. One of the characteristics of responsible AI systems is their explainability. In the paper, we are interested in explainable deep learning (XDL) systems. On the basis of the creation of digital twins of physical objects, we introduce the idea of creating readable twins (in the form of imprecise information flow models) for unreadable deep learning models. The complete procedure for switching from the deep learning model (DLM) to the imprecise information flow model (IIFM) is presented. The proposed approach is illustrated with an example of a deep learning classification model for image recognition of handwritten digits from the MNIST data set.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RUKA: Rethinking the Design of Humanoid Hands with Learning</title>
      <link>/paper/ruka-rethinking-the-design-of-humanoid-hands-with-learning-1744973373105-608652/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/ruka-rethinking-the-design-of-humanoid-hands-with-learning-1744973373105-608652/</guid>
      <description>&lt;p&gt;Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand&amp;rsquo;s morphological accuracy. Extensive evaluations demonstrate RUKA&amp;rsquo;s superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA&amp;rsquo;s dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at &lt;a href=&#34;https://ruka-hand.github.io/&#34;&gt;https://ruka-hand.github.io/&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sleep-time Compute: Beyond Inference Scaling at Test-time</title>
      <link>/paper/sleep-time-compute-beyond-inference-scaling-at-test-time-1744973373105-848179/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/sleep-time-compute-beyond-inference-scaling-at-test-time-1744973373105-848179/</guid>
      <description>&lt;p&gt;Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to &amp;quot;think&amp;quot; offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo</title>
      <link>/paper/syntactic-and-semantic-control-of-large-language-models-via-sequential-monte-carlo-1744973373106-136370/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/syntactic-and-semantic-control-of-large-language-models-via-sequential-monte-carlo-1744973373106-136370/</guid>
      <description>&lt;p&gt;A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution &amp;ndash; which can differ substantially from the LM&amp;rsquo;s base distribution &amp;ndash; is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains &amp;ndash; Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis &amp;ndash; we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transfer Learning via Auxiliary Labels with Application to Cold-Hardiness Prediction</title>
      <link>/paper/transfer-learning-via-auxiliary-labels-with-application-to-cold-hardiness-prediction-1744973373106-530803/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/transfer-learning-via-auxiliary-labels-with-application-to-cold-hardiness-prediction-1744973373106-530803/</guid>
      <description>&lt;p&gt;Cold temperatures can cause significant frost damage to fruit crops depending on their resilience, or cold hardiness, which changes throughout the dormancy season. This has led to the development of predictive cold-hardiness models, which help farmers decide when to deploy expensive frost-mitigation measures. Unfortunately, cold-hardiness data for model training is only available for some fruit cultivars due to the need for specialized equipment and expertise. Rather, farmers often do have years of phenological data (e.g. date of budbreak) that they regularly collect for their crops. In this work, we introduce a new transfer-learning framework, Transfer via Auxiliary Labels (TAL), that allows farmers to leverage the phenological data to produce more accurate cold-hardiness predictions, even when no cold-hardiness data is available for their specific crop. The framework assumes a set of source tasks (cultivars) where each has associated primary labels (cold hardiness) and auxiliary labels (phenology). However, the target task (new cultivar) is assumed to only have the auxiliary labels. The goal of TAL is to predict primary labels for the target task via transfer from the source tasks. Surprisingly, despite the vast literature on transfer learning, to our knowledge, the TAL formulation has not been previously addressed. Thus, we propose several new TAL approaches based on model selection and averaging that can leverage recent deep multi-task models for cold-hardiness prediction. Our results on real-world cold-hardiness and phenological data for multiple grape cultivars demonstrate that TAL can leverage the phenological data to improve cold-hardiness predictions in the absence of cold-hardiness data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation</title>
      <link>/paper/vita-zero-zero-shot-visuotactile-object-6d-pose-estimation-1744973373104-894907/</link>
      <pubDate>Fri, 18 Apr 2025 10:49:33 +0000</pubDate>
      <guid>/paper/vita-zero-zero-shot-visuotactile-object-6d-pose-estimation-1744973373104-894907/</guid>
      <description>&lt;p&gt;Object 6D pose estimation is a critical challenge in robotics, particularly for manipulation tasks. While prior research combining visual and tactile (visuotactile) information has shown promise, these approaches often struggle with generalization due to the limited availability of visuotactile data. In this paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation framework. Our key innovation lies in leveraging a visual model as its backbone and performing feasibility checking and test-time optimization based on physical constraints derived from tactile and proprioceptive observations. Specifically, we model the gripper-object interaction as a spring-mass system, where tactile sensors induce attractive forces, and proprioception generates repulsive forces. We validate our framework through experiments on a real-world robot setup, demonstrating its effectiveness across representative visual backbones and manipulation scenarios, including grasping, object picking, and bimanual handover. Compared to the visual models, our approach overcomes some drastic failure modes while tracking the in-hand object pose. In our experiments, our approach shows an average increase of 55% in AUC of ADD-S and 60% in ADD, along with an 80% lower position error compared to FoundationPose.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
