<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Ml | AI Digest</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/tags/ml/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="//localhost:1313/tags/ml/index.xml">
<link rel="alternate" hreflang="en" href="//localhost:1313/tags/ml/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="//localhost:1313/" accesskey="h" title="AI Digest (Alt + H)">AI Digest</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="//localhost:1313/paper/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="//localhost:1313/video/" title="Videos">
                    <span>Videos</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Ml
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding
    </h2>
  </header>
  <div class="entry-content">
    <p>Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about ‚Äúwhat‚Äù, ‚Äúwhere‚Äù, ‚Äúwhen‚Äù, and ‚Äúhow‚Äù of a video. We make our work fully reproducible by providing data, training recipes, code &amp; models.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding" href="//localhost:1313/paper/perceptionlm-open-access-data-and-models-for-detailed-visual-understanding-1744969749750-453771/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Quantum algorithm for solving nonlinear differential equations based on physics-informed effective Hamiltonians
    </h2>
  </header>
  <div class="entry-content">
    <p>We propose a distinct approach to solving linear and nonlinear differential equations (DEs) on quantum computers by encoding the problem into ground states of effective Hamiltonian operators. Our algorithm relies on constructing such operators in the Chebyshev space, where an effective Hamiltonian is a sum of global differential and data constraints. Once the effective Hamiltonian is formed, solutions of differential equations can be obtained using the ground state preparation techniques (e.g. imaginary-time evolution and quantum singular value transformation), bypassing variational search. Unlike approaches based on discrete grids, the algorithm enables evaluation of solutions beyond fixed grid points and implements constraints in the physics-informed way. Our proposal inherits the best traits from quantum machine learning-based DE solving (compact basis representation, automatic differentiation, nonlinearity) and quantum linear algebra-based approaches (fine-grid encoding, provable speed-up for state preparation), offering a robust strategy for quantum scientific computing in the early fault-tolerant era.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Quantum algorithm for solving nonlinear differential equations based on physics-informed effective Hamiltonians" href="//localhost:1313/paper/quantum-algorithm-for-solving-nonlinear-differential-equations-based-on-physics-informed-effective-hamiltonians-1744969749750-129177/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Readable Twins of Unreadable Models
    </h2>
  </header>
  <div class="entry-content">
    <p>Creating responsible artificial intelligence (AI) systems is an important issue in contemporary research and development of works on AI. One of the characteristics of responsible AI systems is their explainability. In the paper, we are interested in explainable deep learning (XDL) systems. On the basis of the creation of digital twins of physical objects, we introduce the idea of creating readable twins (in the form of imprecise information flow models) for unreadable deep learning models. The complete procedure for switching from the deep learning model (DLM) to the imprecise information flow model (IIFM) is presented. The proposed approach is illustrated with an example of a deep learning classification model for image recognition of handwritten digits from the MNIST data set.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Readable Twins of Unreadable Models" href="//localhost:1313/paper/readable-twins-of-unreadable-models-1744969749750-640829/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Role of AI in Predictive Modeling #ai #artificialintelligence #machinelearning #aiagent #Role
    </h2>
  </header>
  <div class="entry-content">
    <p>genaiexp Artificial Intelligence plays a crucial role in predictive modeling by leveraging machine learning algorithms to analyze ‚Ä¶
</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Role of AI in Predictive Modeling #ai #artificialintelligence #machinelearning #aiagent #Role" href="//localhost:1313/video/role-of-ai-in-predictive-modeling-ai-artificialintelligence-machinelearning-aiagent-role-1744969749750-813571/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RUKA: Rethinking the Design of Humanoid Hands with Learning
    </h2>
  </header>
  <div class="entry-content">
    <p>Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand‚Äôs morphological accuracy. Extensive evaluations demonstrate RUKA‚Äôs superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA‚Äôs dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at https://ruka-hand.github.io/.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to RUKA: Rethinking the Design of Humanoid Hands with Learning" href="//localhost:1313/paper/ruka-rethinking-the-design-of-humanoid-hands-with-learning-1744969749750-910990/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Sleep-time Compute: Beyond Inference Scaling at Test-time
    </h2>
  </header>
  <div class="entry-content">
    <p>Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to ‚Äúthink‚Äù offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;2 min</footer>
  <a class="entry-link" aria-label="post link to Sleep-time Compute: Beyond Inference Scaling at Test-time" href="//localhost:1313/paper/sleep-time-compute-beyond-inference-scaling-at-test-time-1744969749750-446779/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo
    </h2>
  </header>
  <div class="entry-content">
    <p>A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution ‚Äì which can differ substantially from the LM‚Äôs base distribution ‚Äì is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains ‚Äì Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis ‚Äì we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo" href="//localhost:1313/paper/syntactic-and-semantic-control-of-large-language-models-via-sequential-monte-carlo-1744969749750-290642/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">The video was created using artificial intelligence. #aiartmodellookbook #aiart #boxgirl boxgi
    </h2>
  </header>
  <div class="entry-content">
    <p>No description provided.
</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.75 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to The video was created using artificial intelligence. #aiartmodellookbook #aiart #boxgirl boxgi" href="//localhost:1313/video/the-video-was-created-using-artificial-intelligence-aiartmodellookbook-aiart-boxgirl-boxgi-1744969749750-749357/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">This Robot Fixes Itself After Getting Damaged üò≥ #shorts #futuretech #artificialintelligence
    </h2>
  </header>
  <div class="entry-content">
    <p>No description provided.
</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.751 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to This Robot Fixes Itself After Getting Damaged üò≥ #shorts #futuretech #artificialintelligence" href="//localhost:1313/video/this-robot-fixes-itself-after-getting-damaged-shorts-futuretech-artificialintelligence-1744969749750-867182/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Top Artificial Intelligence and Data Science Course in Chennai
    </h2>
  </header>
  <div class="entry-content">
    <p>AI Made Easy! Dreaming of a career in Artificial Intelligence or Data Science? Now you can learn cutting-edge AI tech affordably ‚Ä¶
</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-18 09:49:09.751 +0000 UTC'>April 18, 2025</span>&nbsp;¬∑&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to Top Artificial Intelligence and Data Science Course in Chennai" href="//localhost:1313/video/top-artificial-intelligence-and-data-science-course-in-chennai-1744969749751-953741/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="//localhost:1313/tags/ml/page/4/">
      ¬´&nbsp;Prev&nbsp;
    </a>
    <a class="next" href="//localhost:1313/tags/ml/page/6/">Next&nbsp;&nbsp;¬ª
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="//localhost:1313/">AI Digest</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
