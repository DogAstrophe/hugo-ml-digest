---
title: "Antidistillation Sampling"
date: 2025-04-18T09:40:08.274Z
source: paper
link: "http://arxiv.org/abs/2504.13146v1"
tags: ["paper","ml"]
---
Frontier models that generate extended reasoning traces inadvertently produce
rich token sequences that can facilitate model distillation. Recognizing this
vulnerability, model owners may seek sampling strategies that limit the
effectiveness of distillation without compromising model performance.
\emph{Antidistillation sampling} provides exactly this capability. By
strategically modifying a model's next-token probability distribution,
antidistillation sampling poisons reasoning traces, rendering them
significantly less effective for distillation while preserving the model's
practical utility. For further details, see https://antidistillation.com.
